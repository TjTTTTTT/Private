{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "12b24c27-7358-4650-b3c8-ed08ee88901c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 填充缺失值\n",
    "# import pandas as pd\n",
    "# # 加载数据集\n",
    "# penguins_data = pd.read_csv('E:/Desktop/AI/penguins.csv')\n",
    "\n",
    "# # 定义填充函数，对不同的数值型数据使用不同的小数位数填充\n",
    "# def fill_with_group_stats(df, group_cols, fill_cols, decimal_places):\n",
    "#     # 对数值型数据使用指定的小数位数填充\n",
    "#     for col in fill_cols['mean']:\n",
    "#         if col in decimal_places:\n",
    "#             # 使用指定的小数位数四舍五入\n",
    "#             df[col] = df.groupby(group_cols)[col].transform(lambda x: x.fillna(round(x.mean(), decimal_places[col])))\n",
    "#         else:\n",
    "#             # 默认不四舍五入，使用原始均值\n",
    "#             df[col] = df.groupby(group_cols)[col].transform(lambda x: x.fillna(x.mean()))\n",
    "#     # 对分类型数据使用众数填充\n",
    "#     for col in fill_cols['mode']:\n",
    "#         df[col] = df.groupby(group_cols)[col].transform(lambda x: x.fillna(x.mode()[0] if not x.mode().empty else None))\n",
    "#     return df\n",
    "\n",
    "# # 应用填充函数\n",
    "# group_columns = ['species', 'island', 'year']\n",
    "# fill_columns = {\n",
    "#     'mean': ['bill_length_mm', 'bill_depth_mm', 'flipper_length_mm', 'body_mass_g'], \n",
    "#     'mode': ['sex']\n",
    "# }\n",
    "# decimal_places = {\n",
    "#     'bill_length_mm': 1,\n",
    "#     'bill_depth_mm': 1,\n",
    "#     'flipper_length_mm': 0,\n",
    "#     'body_mass_g': 0\n",
    "# }\n",
    "\n",
    "# penguins_data = fill_with_group_stats(penguins_data, group_columns, fill_columns, decimal_places)\n",
    "\n",
    "# # Save the updated dataset to a CSV file\n",
    "# penguins_data.to_csv('E:/Desktop/AI/updated_penguins.csv', index=False)\n",
    "\n",
    "# # 检查是否还有剩余的缺失值\n",
    "# updated_missing_data = penguins_data.isnull().sum()\n",
    "# print(updated_missing_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "2db725b9-9053-4e8e-8d0e-52f141c87f34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 查看有无异常值，发现很少\n",
    "# import pandas as pd\n",
    "# import seaborn as sns\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# # 加载数据集\n",
    "# penguins_data = pd.read_csv('E:/Desktop/AI/updated_penguins.csv')\n",
    "\n",
    "# # 定义检查异常值的函数\n",
    "# def plot_boxplots(df, group_cols, numeric_cols):\n",
    "#     # 为每个数值型字段生成一个箱形图\n",
    "#     for col in numeric_cols:\n",
    "#         plt.figure(figsize=(12, 6))\n",
    "#         sns.boxplot(data=df, x='species', y=col, hue='island')\n",
    "#         plt.title(f'Boxplot of {col} grouped by Species and Island')\n",
    "#         plt.xlabel('Species')\n",
    "#         plt.ylabel(col)\n",
    "#         plt.legend(title='Island')\n",
    "#         plt.show()\n",
    "\n",
    "# # 调用函数生成箱形图\n",
    "# numeric_columns = ['bill_length_mm', 'bill_depth_mm', 'flipper_length_mm', 'body_mass_g']\n",
    "# plot_boxplots(penguins_data, ['species', 'island'], numeric_columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c3e1141-4276-4c7a-a9a9-075ba89cca51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "\n",
    "# # 加载数据集\n",
    "# penguins = pd.read_csv('E:/Desktop/AI/updated_penguins.csv')\n",
    "\n",
    "# # 按物种和岛屿分组，并对选定的数值列计算平均值\n",
    "# grouped_means = penguins.groupby(['species', 'island'])[['bill_length_mm', 'bill_depth_mm', 'flipper_length_mm', 'body_mass_g']].mean()\n",
    "# # grouped_means.to_csv('E:/Desktop/AI/grouped_means.csv')\n",
    "# latex_table = grouped_means.to_latex()\n",
    "# print(latex_table)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "834b8110-feae-4415-85d4-51fecdc7c570",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # # # 使用Kmeans聚类，获得聚类标签\n",
    "# import pandas as pd\n",
    "# from sklearn.cluster import KMeans\n",
    "# from sklearn.preprocessing import StandardScaler\n",
    "# from sklearn.decomposition import PCA\n",
    "# import matplotlib.pyplot as plt\n",
    "# from sklearn.metrics import silhouette_score\n",
    "# # 加载数据集\n",
    "# penguins_data = pd.read_csv('E:/Desktop/AI/updated_penguins.csv')\n",
    "\n",
    "# # 选择特征\n",
    "# features = penguins_data[['bill_length_mm', 'bill_depth_mm', 'flipper_length_mm', 'body_mass_g']]\n",
    "\n",
    "# # 数据标准化\n",
    "# scaler = StandardScaler()\n",
    "# features_scaled = scaler.fit_transform(features)\n",
    "\n",
    "# # 应用K-Means聚类\n",
    "# kmeans = KMeans(n_clusters=3, random_state=42)\n",
    "# kmeans.fit(features_scaled)\n",
    "\n",
    "# # 获得聚类标签\n",
    "# penguins_data['cluster'] = kmeans.labels_\n",
    "\n",
    "# # # 计算轮廓系数\n",
    "# # score = silhouette_score(features_scaled, kmeans.labels_)\n",
    "# # print('Silhouette Score: %.2f' % score)\n",
    "\n",
    "# # # PCA降维到2D用于可视化\n",
    "# # pca = PCA(n_components=2)\n",
    "# # principal_components = pca.fit_transform(features_scaled)\n",
    "\n",
    "# # # 可视化\n",
    "# # plt.figure(figsize=(8, 6))\n",
    "# # plt.scatter(principal_components[:, 0], principal_components[:, 1], c=penguins_data['cluster'], cmap='viridis', marker='o')\n",
    "# # plt.title('PCA of Penguin Dataset with K-Means Clustering')\n",
    "# # plt.xlabel('Principal Component 1')\n",
    "# # plt.ylabel('Principal Component 2')\n",
    "# # plt.colorbar(label='Cluster')\n",
    "# # plt.show()\n",
    "\n",
    "# # # penguins_data.to_csv('E:/Desktop/AI/Kmeans_penguins.csv', index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "73ab1a2f-dba1-4963-a912-94e0b51c5d02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # # 把文件分为训练集、验证集和测试集时，比例为70%（训练集）:15%（验证集）:15%（测试集）\n",
    "# import pandas as pd\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# from sklearn.model_selection import GridSearchCV\n",
    "# from sklearn.svm import SVC\n",
    "# from sklearn.ensemble import RandomForestClassifier\n",
    "# from sklearn.metrics import classification_report\n",
    "\n",
    "# # 加载数据集\n",
    "# data = pd.read_csv('E:/Desktop/AI/KmeansRevise_penguins.csv')\n",
    "\n",
    "# # 假设'cluster'是您通过K-Means修正后的目标分类标签\n",
    "# features = data[['bill_length_mm', 'bill_depth_mm', 'flipper_length_mm', 'body_mass_g']]\n",
    "# labels = data['cluster']\n",
    "\n",
    "# # 分割数据集为训练集和临时集（包含验证集和测试集）\n",
    "# X_train, X_temp, y_train, y_temp = train_test_split(features, labels, test_size=0.3, random_state=42)\n",
    "\n",
    "# # 从临时集中分割出验证集和测试集\n",
    "# X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8ebc2c5-e18b-48e3-9178-23bf850e673d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 寻找最优超参数\n",
    "# # 假设X_train, y_train, X_val, y_val已经定义\n",
    "# # 定义SVM和随机森林的超参数网格\n",
    "\n",
    "# param_grid_svm = {\n",
    "#     # 'C': [1, 1.5, 1.7,2],\n",
    "#     'C': [1.6,1.7,1.8,1.9,2],\n",
    "#     'kernel': ['linear', 'rbf', 'poly']\n",
    "# }\n",
    "\n",
    "# param_grid_rf = {\n",
    "#     # 'n_estimators': [85, 100, 175,50,70,65],\n",
    "#     'n_estimators': [75,85,90],\n",
    "#     'max_features': ['auto', 'sqrt', 'log2'],\n",
    "#     'max_depth': [None,2,4]\n",
    "# }\n",
    "\n",
    "# # 创建SVM模型的GridSearchCV对象\n",
    "# # grid_search_svm = GridSearchCV(SVC(), param_grid_svm, refit=True, verbose=0)\n",
    "# # grid_search_svm.fit(X_train, y_train)\n",
    "# # print(\"Best parameters for SVM:\", grid_search_svm.best_params_)\n",
    "\n",
    "# # 创建随机森林模型的GridSearchCV对象\n",
    "# grid_search_rf = GridSearchCV(RandomForestClassifier(random_state=42), param_grid_rf, refit=True, verbose=0)\n",
    "# grid_search_rf.fit(X_train, y_train)\n",
    "# print(\"Best parameters for Random Forest:\", grid_search_rf.best_params_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "daa98879-75e3-4150-be58-6f03b3a86d9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# from sklearn.model_selection import cross_val_score, train_test_split\n",
    "# from sklearn.svm import SVC\n",
    "# from sklearn.ensemble import RandomForestClassifier\n",
    "# from sklearn.preprocessing import StandardScaler\n",
    "# from sklearn.pipeline import make_pipeline\n",
    "# from sklearn.metrics import accuracy_score, f1_score\n",
    "# from sklearn.dummy import DummyClassifier  # 导入DummyClassifier\n",
    "\n",
    "# # 加载数据集\n",
    "# data = pd.read_csv('E:/Desktop/AI/KmeansRevise_penguins.csv')\n",
    "\n",
    "# # 准备特征和标签\n",
    "# features = data[['bill_length_mm', 'bill_depth_mm', 'flipper_length_mm', 'body_mass_g']]\n",
    "# labels = data['cluster']\n",
    "# X_train_val, X_test, y_train_val, y_test = train_test_split(features, labels, test_size=0.15, random_state=42)\n",
    "\n",
    "# # 创建模型\n",
    "# svm_model = make_pipeline(StandardScaler(), SVC(kernel='linear', C=1.7))\n",
    "# rf_model = RandomForestClassifier(n_estimators=85, max_features='sqrt', max_depth=None, random_state=42)\n",
    "# baseline_model = DummyClassifier(strategy='most_frequent')  # 创建基线模型\n",
    "\n",
    "# # 执行5折交叉验证\n",
    "# svm_scores = cross_val_score(svm_model, X_train_val, y_train_val, cv=5)\n",
    "# rf_scores = cross_val_score(rf_model, X_train_val, y_train_val, cv=5)\n",
    "\n",
    "# # 打印交叉验证结果\n",
    "# print(\"Average SVM Cross-validated score:\", svm_scores.mean())\n",
    "# print(\"Average Random Forest Cross-validated score:\", rf_scores.mean())\n",
    "\n",
    "# # 重新训练模型在整个训练验证集上\n",
    "# svm_model.fit(X_train_val, y_train_val)\n",
    "# rf_model.fit(X_train_val, y_train_val)\n",
    "# baseline_model.fit(X_train_val, y_train_val)  # 训练基线模型\n",
    "\n",
    "# # 测试集上的最终评估\n",
    "# svm_test_predictions = svm_model.predict(X_test)\n",
    "# rf_test_predictions = rf_model.predict(X_test)\n",
    "# baseline_test_predictions = baseline_model.predict(X_test)  # 预测基线模型\n",
    "\n",
    "# # 计算准确率和F1分数\n",
    "# svm_test_accuracy = accuracy_score(y_test, svm_test_predictions)\n",
    "# rf_test_accuracy = accuracy_score(y_test, rf_test_predictions)\n",
    "# baseline_test_accuracy = accuracy_score(y_test, baseline_test_predictions)  # 基线模型准确率\n",
    "\n",
    "# svm_test_f1 = f1_score(y_test, svm_test_predictions, average='macro')\n",
    "# rf_test_f1 = f1_score(y_test, rf_test_predictions, average='macro')\n",
    "# baseline_test_f1 = f1_score(y_test, baseline_test_predictions, average='macro')  # 基线模型F1分数\n",
    "\n",
    "# # 打印测试集准确率和F1分数\n",
    "# print(\"SVM Test accuracy:\", svm_test_accuracy)\n",
    "# print(\"Random Forest Test accuracy:\", rf_test_accuracy)\n",
    "# print(\"Baseline Model Test accuracy:\", baseline_test_accuracy)  # 打印基线模型准确率\n",
    "\n",
    "# print(\"SVM Test F1 Score:\", svm_test_f1)\n",
    "# print(\"Random Forest Test F1 Score:\", rf_test_f1)\n",
    "# print(\"Baseline Model Test F1 Score:\", baseline_test_f1)  # 打印基线模型F1分数\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "556d743e-6d01-44e1-8872-acfd3613f1a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 企鹅频率直方图（放弃）\n",
    "# import pandas as pd\n",
    "# import matplotlib.pyplot as plt\n",
    "# import seaborn as sns\n",
    "\n",
    "# # 加载数据\n",
    "# data = pd.read_csv('E:/Desktop/AI/updated_penguins.csv')\n",
    "\n",
    "# # 设置绘图风格为白色背景，以提高图表的整体美观\n",
    "# sns.set_style(\"white\")\n",
    "\n",
    "# # 计算每个种类在每个岛屿上的计数\n",
    "# grouped_data = data.groupby(['species', 'island']).size().unstack(fill_value=0)\n",
    "\n",
    "# # 创建分组柱状图，柱子更细且间距更近\n",
    "# ax = grouped_data.plot(kind='bar', stacked=True, figsize=(7, 6), width=0.4, colormap='viridis')\n",
    "\n",
    "# # 设置图表标题和轴标签\n",
    "# # ax.set_title('Frequency Distribution of Penguin Species Across Islands', fontsize=14)\n",
    "# ax.set_xlabel('Species', fontsize=12)\n",
    "# ax.set_ylabel('Frequency', fontsize=12)\n",
    "# ax.set_xticklabels(ax.get_xticklabels(), rotation=0)\n",
    "\n",
    "# # 添加图例\n",
    "# ax.legend(title='Island', loc='upper right', frameon=False)\n",
    "\n",
    "# # 移除周围的边框\n",
    "# for spine in ax.spines.values():\n",
    "#     spine.set_visible(False)\n",
    "\n",
    "# # 在每组柱子的最顶端显示总计数量\n",
    "# for i, (species, row) in enumerate(grouped_data.iterrows()):\n",
    "#     total = row.sum()  # 计算每个种类的总频率\n",
    "#     x = i  # 柱子的位置\n",
    "#     if total > 0:  # 仅当总数大于0时标注\n",
    "#         ax.annotate(f'{int(total)}', (x, total), ha='center', va='bottom', color='black', fontsize=9)\n",
    "\n",
    "# # 移除网格线\n",
    "# ax.grid(False)\n",
    "\n",
    "# # 显示并且保存图表\n",
    "# plt.tight_layout()\n",
    "# plt.savefig('E:/Desktop/AI/1.pdf')\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "c3d0673d-0388-4f27-8360-a4544409ddeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 属性散点图（放弃）\n",
    "# import pandas as pd\n",
    "# import seaborn as sns\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# # 加载数据\n",
    "# data = pd.read_csv('E:/Desktop/AI/updated_penguins.csv')\n",
    "\n",
    "# # 使用seaborn的lmplot来绘制散点图，但不拟合线性回归模型\n",
    "# plot = sns.lmplot(x='flipper_length_mm', y='bill_length_mm', hue='species', data=data,\n",
    "#                   fit_reg=False, markers=['o', 's', '^'], palette='bright', height=6, aspect=1.5, legend=False)\n",
    "\n",
    "# # 设置标题和轴标签\n",
    "# plt.title('Relationship between Flipper Length and Bill Length by Penguin Species')\n",
    "# plt.xlabel('Flipper Length (mm)')\n",
    "# plt.ylabel('Bill Length (mm)')\n",
    "\n",
    "# # 调整图例位置并去除图例边框\n",
    "# plt.legend(title='Penguin species', frameon=False)\n",
    "\n",
    "# # 使用tight_layout来自动调整子图参数\n",
    "# plt.tight_layout()\n",
    "\n",
    "# # 保存图表为PDF，确保整个图表区域被保存\n",
    "# plot.savefig('E:/Desktop/AI/2.pdf', bbox_inches='tight')\n",
    "\n",
    "# # 显示图表\n",
    "# plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "text_analytics",
   "language": "python",
   "name": "text_analytics"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
